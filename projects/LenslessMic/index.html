<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> LenslessMic | Petr Grinberg </title> <meta name="author" content="Petr Grinberg"> <meta name="description" content="Audio Encryption and Authentication via Lensless Computational Imaging -- Official Demo Page."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-table@1.22.4/dist/bootstrap-table.min.css" integrity="sha256-uRX+PiRTR4ysKFRCykT8HLuRCub26LgXJZym3Yeom1c=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://blinorot.github.io/projects/LenslessMic/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Petr</span> Grinberg </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/projects/">projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/teaching/">teaching</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/publications/">publications</a> <div class="dropdown-divider"></div> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">LenslessMic</h1> <p class="post-description">Audio Encryption and Authentication via Lensless Computational Imaging -- Official Demo Page.</p> </header> <article> <div class="authors mb-3"> <strong>Petr Grinberg</strong>, Eric Bezzam, Paolo Prandoni, Martin Vetterli </div> <div class="affiliations mb-2"> Audiovisual Communications Laboratory, EPFL, Switzerland </div> <div class="emails mb-4"> ✉ <a href="mailto:petr.grinberg@epfl.ch">petr.grinberg@epfl.ch</a> </div> <div class="d-flex flex-wrap gap-2 my-3"> <a class="btn btn-dark" href="https://github.com/Blinorot/LenslessMic" target="_blank" rel="noopener"> <i class="fab fa-github"></i> Code </a> <a class="btn btn-danger" href="https://arxiv.org/abs/2509.16418" target="_blank" rel="noopener"> <i class="ai ai-arxiv"></i> arXiv </a> <a class="btn btn-outline-warning d-inline-flex align-items-center" href="https://huggingface.co/collections/Blinorot/lenslessmic-68caf4f8ff7fa56c2dac8540" target="_blank" rel="noopener"> <img src="https://huggingface.co/front/assets/huggingface_logo.svg" alt="HF" style="height:1em; width:auto; margin-right:0.4em;"> Hugging Face Collection </a> </div> <blockquote> <p>With society’s increasing reliance on digital data sharing, the protection of sensitive information has become critical. Encryption serves as one of the privacy-preserving methods; however, its realization in the audio domain predominantly relies on signal processing or software methods embedded into hardware. In this paper, we introduce LenslessMic, a hybrid optical hardware-based encryption method that utilizes a lensless camera as a physical layer of security applicable to multiple types of audio. We show that LenslessMic enables (1) robust authentication of audio recordings and (2) encryption strength that can rival the search space of 256-bit digital standards, while maintaining high-quality signals and minimal loss of content information. The approach is validated with a low-cost Raspberry Pi prototype and is open-sourced together with datasets to facilitate research in the area.</p> </blockquote> <h2 id="hardware-setup">Hardware Setup</h2> <p>Our setup is based on <a href="https://arxiv.org/abs/2502.01102" rel="external nofollow noopener" target="_blank">DigiCam</a>. We adapt it to show neural audio codec latent representation. During capture process, we cover the system with a black cloth to prevent external illumination.</p> <div class="row mt-3"> <div class="col-md-6 d-flex align-items-center justify-content-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/LenslessMic/images/DigiCam_LenslessMic_setup-480.webp 480w,/assets/LenslessMic/images/DigiCam_LenslessMic_setup-800.webp 800w,/assets/LenslessMic/images/DigiCam_LenslessMic_setup-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/LenslessMic/images/DigiCam_LenslessMic_setup.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-md-6"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/LenslessMic/images/DigiCam_LenslessMic-480.webp 480w,/assets/LenslessMic/images/DigiCam_LenslessMic-800.webp 800w,/assets/LenslessMic/images/DigiCam_LenslessMic-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/LenslessMic/images/DigiCam_LenslessMic.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <em>LenslessMic</em> hardware setup. Latent representation is reshaped and resized into a large square with super-pixels. </div> <h2 id="demo-samples">Demo Samples</h2> <p>Below we show example audio from the collected <a href="https://www.openslr.org/12" rel="external nofollow noopener" target="_blank">Librispeech</a> and <a href="https://github.com/mulab-mir/song-describer-dataset" rel="external nofollow noopener" target="_blank">SongDescriber</a> datasets for different models: <em>Learned</em> (with different \(g, r\) variations), <em>R-Learned</em>, <em>NoPSF</em>, and <em>ADMM-100</em>.</p> <p>All models and train/test datasets are published on <a href="https://huggingface.co/collections/Blinorot/lenslessmic-68caf4f8ff7fa56c2dac8540" rel="external nofollow noopener" target="_blank">Huggingface Collection</a>.</p> <ul> <li> <em>Learned</em>: a trainable reconstruction algorithm based on <a href="https://arxiv.org/abs/1908.11502" rel="external nofollow noopener" target="_blank">Unrolled ADMM</a>. Uses <a href="https://arxiv.org/abs/2008.13751" rel="external nofollow noopener" target="_blank">DRUNet</a>-based pre/post processors (3.9/4.1M parameters) and psf corrector (128K parameters) to account for noise and model mismatch (8.1M parameters total). Trained on <em>train-clean</em> set.</li> <li> <em>R-Learned</em>: the same as <em>Learned</em> but trained on <em>train-random</em>.</li> <li> <em>NoPSF</em>: a trainable reconstruction algorithm that uses only (codec representation, lensless measurement) pairs for training and <strong>does not use PSF in any way</strong>. Based on DRUNet with 8.1M parameters. Trained on <em>train-clean</em> set.</li> <li> <em>ADMM-100</em>: vanilla reconstruction algorithm that uses <a href="https://arxiv.org/abs/1710.02134" rel="external nofollow noopener" target="_blank">Alternating Direction Method of Multipliers</a> with 100 iterations.</li> </ul> <h3 id="audio-reconstruction">Audio Reconstruction</h3> <script>
// Renders a compact audio player; returns HTML for each cell
function audioFormatter(value, row, index) {
  if (!value) return '<span class="text-muted">—</span>';
  // Use a small, consistent size; preload=none keeps the page light
  return `
    <audio controls preload="none" style="width:160px;">
      <source src="${value}" type="audio/mpeg">
      Your browser does not support the audio element.
    </audio>`;
}
</script> <link rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.3/dist/bootstrap-table.min.css"> <script src="https://unpkg.com/bootstrap-table@1.22.3/dist/bootstrap-table.min.js"></script> <p>Below we provide recordings from <em>test-clean</em> set of Librispeech. <strong><u>We recommend listening to the ground-truth and codec versions only after listening to the reconstructions to avoid phonetic-restoration effect</u></strong>, i.e. unintelligible audio may become meaningful after you know what is the actual content of the speech. Methods with \(g \ge 2\) increase <em>LenslessMic</em> robustness to ensure that this effect will not allow hearing speech content from <em>NoPSF</em> reconstructions.</p> <table id="audio-table" data-toggle="table" data-search="false" data-pagination="true" data-url="/assets/json/LenslessMic/test_clean_all.json" data-height="700"> <thead> <tr> <th data-field="method" data-sortable="true">Method</th> <th data-field="237-126133-0018" data-formatter="audioFormatter" data-halign="center" data-align="center">237-126133-0018</th> <th data-field="4446-2273-0026" data-formatter="audioFormatter" data-halign="center" data-align="center">4446-2273-0026</th> <th data-field="5105-28241-0013" data-formatter="audioFormatter" data-halign="center" data-align="center">5105-28241-0013</th> <th data-field="5142-33396-0062" data-formatter="audioFormatter" data-halign="center" data-align="center">5142-33396-0062</th> <th data-field="7127-75947-0032" data-formatter="audioFormatter" data-halign="center" data-align="center">7127-75947-0032</th> <th data-field="8455-210777-0042" data-formatter="audioFormatter" data-halign="center" data-align="center">8455-210777-0042</th> </tr> </thead> </table> <p><em>Learned</em> and <em>Codec</em> recordings sound very similar, showcasing high quality reconstruction abilities of <em>LenslessMic</em>. Since it may be possible to understand some part of the speech content for <em>NoPSF</em>, we provide <em>LenslessMic</em> variants with improved robustness that operate on grouped frames. The examples are provided below. \(g=3\) case provides the best balance between security robustness and reconstruction quality.</p> <table id="audio-table" data-toggle="table" data-search="false" data-pagination="true" data-url="/assets/json/LenslessMic/test_clean_all_group.json" data-height="760"> <thead> <tr> <th data-field="method" data-sortable="true">Method</th> <th data-field="237-126133-0018" data-formatter="audioFormatter" data-halign="center" data-align="center">237-126133-0018</th> <th data-field="4446-2273-0026" data-formatter="audioFormatter" data-halign="center" data-align="center">4446-2273-0026</th> <th data-field="5105-28241-0013" data-formatter="audioFormatter" data-halign="center" data-align="center">5105-28241-0013</th> <th data-field="5142-33396-0062" data-formatter="audioFormatter" data-halign="center" data-align="center">5142-33396-0062</th> <th data-field="7127-75947-0032" data-formatter="audioFormatter" data-halign="center" data-align="center">7127-75947-0032</th> <th data-field="8455-210777-0042" data-formatter="audioFormatter" data-halign="center" data-align="center">8455-210777-0042</th> </tr> </thead> </table> <p>We test whether <em>LenslessMic</em> is applicable to other neural audio codecs and collect a dataset with X-codec instead of DAC. The results are presented below. While some utterances sound almost as good as DAC-ones, there are several recordings that have severe reverberation-like or filtering-like effect that decreases intelligibility. In general, <em>LenslessMic</em> is applicable on other codecs and even in cross-codec scenario, however, training on the actual data is required for high-quality reconstruction. <em>R-Learned</em> achieves better quality because it is trained on <em>test-random</em> data and is not overfitted towards any single codec.</p> <table id="audio-table" data-toggle="table" data-search="false" data-pagination="true" data-url="/assets/json/LenslessMic/test_clean_all_xcodec.json" data-height="430"> <thead> <tr> <th data-field="method" data-sortable="true">Method</th> <th data-field="237-126133-0018" data-formatter="audioFormatter" data-halign="center" data-align="center">237-126133-0018</th> <th data-field="4446-2273-0026" data-formatter="audioFormatter" data-halign="center" data-align="center">4446-2273-0026</th> <th data-field="5105-28241-0013" data-formatter="audioFormatter" data-halign="center" data-align="center">5105-28241-0013</th> <th data-field="5142-33396-0062" data-formatter="audioFormatter" data-halign="center" data-align="center">5142-33396-0062</th> <th data-field="7127-75947-0032" data-formatter="audioFormatter" data-halign="center" data-align="center">7127-75947-0032</th> <th data-field="8455-210777-0042" data-formatter="audioFormatter" data-halign="center" data-align="center">8455-210777-0042</th> </tr> </thead> </table> <p>Besides, <em>LenslessMic</em> works on music data too (we downsampled dataset to 16kHz, so some instruments are a bit distorted):</p> <table id="audio-table" data-toggle="table" data-search="false" data-pagination="true" data-url="/assets/json/LenslessMic/test_clean_all_music.json" data-height="430"> <thead> <tr> <th data-field="method" data-sortable="true">Method</th> <th data-field="27.599227.6s" data-formatter="audioFormatter" data-halign="center" data-align="center">27.599227.6s</th> <th data-field="33.1336433.6s" data-formatter="audioFormatter" data-halign="center" data-align="center">33.1336433.6s </th> <th data-field="43.175043.6s" data-formatter="audioFormatter" data-halign="center" data-align="center">43.175043.6s</th> <th data-field="46.5346.6s" data-formatter="audioFormatter" data-halign="center" data-align="center">46.5346.6s</th> <th data-field="56.76656.6s" data-formatter="audioFormatter" data-halign="center" data-align="center">56.76656.6s</th> </tr> </thead> </table> <h3 id="audio-encryption-and-authentication">Audio Encryption and Authentication</h3> <div class="row mt-3"> <div class="align-items-center justify-content-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/LenslessMic/images/Pipeline-480.webp 480w,/assets/LenslessMic/images/Pipeline-800.webp 800w,/assets/LenslessMic/images/Pipeline-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/LenslessMic/images/Pipeline.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Overview of the <em>LenslessMic</em> pipeline. Encryption depends on the PSF and reconstruction algorithm cannot recover original recording without knowing the correct PSF. </div> <p><em>LenslessMic</em> reconstruction results in noise if provided PSF is wrong. This is a core property behind <em>LenslessMic</em> authentication robustness and accuracy. Below you can find examples:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/assets/LenslessMic/librispeech/test-clean/reconstructed/test_auth_0/32x32_librispeech_mse_ssim_raw_ssim_PSF_Unet4M_U5_Unet4M/audio/237-126133-0018.wav" controls=""></audio> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/assets/LenslessMic/librispeech/test-clean/reconstructed/test/32x32_librispeech_mse_ssim_raw_ssim_PSF_Unet4M_U5_Unet4M/audio/237-126133-0018.wav" controls=""></audio> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/assets/LenslessMic/librispeech/test-clean/reconstructed/test_auth_0/32x32_librispeech_mse_ssim_raw_ssim_PSF_Unet4M_U5_Unet4M/audio/8455-210777-0042.wav" controls=""></audio> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/assets/LenslessMic/librispeech/test-clean/reconstructed/test/32x32_librispeech_mse_ssim_raw_ssim_PSF_Unet4M_U5_Unet4M/audio/8455-210777-0042.wav" controls=""></audio> </figure> </div> </div> <div class="caption"> The same audio with wrong (left) and correct (right) PSF. <strong>We use the same <em>Learned</em> algorithm here.</strong> </div> <p>Let \(W \in (0, 1]\) be the ratio of correctly determined pixels of the PSF. If the minimum \(W\) required to get an intelligible audio is \(W \ge \frac{K \log_b 2}{N}\), where \(N\) is the number of pixels in the PSF and \(b\) is the bit-depth, then the <em>LenslessMic</em> system has an encryption strength with a search space equivalent to a secret key of size \(K\). Below we provide audio samples for different \(W\). \(W=7\%\) and \(W=4\%\) correspond to AES-256 and AES-128 search space, respectively (We rounded \(W\) to the next integer, so actually \(W=7\) has even bigger search space of \(K=272\)).</p> <p>Results for \(g=3\):</p> <table id="audio-table" data-toggle="table" data-search="false" data-pagination="true" data-url="/assets/json/LenslessMic/test_clean_all_psf_error_g_3.json" data-height="430"> <thead> <tr> <th data-field="method" data-sortable="true">Method</th> <th data-field="237-126133-0018" data-formatter="audioFormatter" data-halign="center" data-align="center">237-126133-0018</th> <th data-field="4446-2273-0026" data-formatter="audioFormatter" data-halign="center" data-align="center">4446-2273-0026</th> <th data-field="5105-28241-0013" data-formatter="audioFormatter" data-halign="center" data-align="center">5105-28241-0013</th> <th data-field="5142-33396-0062" data-formatter="audioFormatter" data-halign="center" data-align="center">5142-33396-0062</th> <th data-field="7127-75947-0032" data-formatter="audioFormatter" data-halign="center" data-align="center">7127-75947-0032</th> <th data-field="8455-210777-0042" data-formatter="audioFormatter" data-halign="center" data-align="center">8455-210777-0042</th> </tr> </thead> </table> <p>Results for \(g=2\):</p> <table id="audio-table" data-toggle="table" data-search="false" data-pagination="true" data-url="/assets/json/LenslessMic/test_clean_all_psf_error_g_2.json" data-height="430"> <thead> <tr> <th data-field="method" data-sortable="true">Method</th> <th data-field="237-126133-0018" data-formatter="audioFormatter" data-halign="center" data-align="center">237-126133-0018</th> <th data-field="4446-2273-0026" data-formatter="audioFormatter" data-halign="center" data-align="center">4446-2273-0026</th> <th data-field="5105-28241-0013" data-formatter="audioFormatter" data-halign="center" data-align="center">5105-28241-0013</th> <th data-field="5142-33396-0062" data-formatter="audioFormatter" data-halign="center" data-align="center">5142-33396-0062</th> <th data-field="7127-75947-0032" data-formatter="audioFormatter" data-halign="center" data-align="center">7127-75947-0032</th> <th data-field="8455-210777-0042" data-formatter="audioFormatter" data-halign="center" data-align="center">8455-210777-0042</th> </tr> </thead> </table> <p>Results for \(g=1\) (i.e. standard <em>Learned</em>):</p> <table id="audio-table" data-toggle="table" data-search="false" data-pagination="true" data-url="/assets/json/LenslessMic/test_clean_all_psf_error_g_1.json" data-height="430"> <thead> <tr> <th data-field="method" data-sortable="true">Method</th> <th data-field="237-126133-0018" data-formatter="audioFormatter" data-halign="center" data-align="center">237-126133-0018</th> <th data-field="4446-2273-0026" data-formatter="audioFormatter" data-halign="center" data-align="center">4446-2273-0026</th> <th data-field="5105-28241-0013" data-formatter="audioFormatter" data-halign="center" data-align="center">5105-28241-0013</th> <th data-field="5142-33396-0062" data-formatter="audioFormatter" data-halign="center" data-align="center">5142-33396-0062</th> <th data-field="7127-75947-0032" data-formatter="audioFormatter" data-halign="center" data-align="center">7127-75947-0032</th> <th data-field="8455-210777-0042" data-formatter="audioFormatter" data-halign="center" data-align="center">8455-210777-0042</th> </tr> </thead> </table> <p>We hear that recovering speech content (without phonetic-restoration effect) and speaker identity with \(W=7\%\) is not possible for \(g=1\) too. Besides, the audio still resembles noise. Therefore, the intruder cannot hack the authentication algorithm presented above via a brute-force attack.</p> <p>\(g=3\) is more robust, however, leads to slightly worse reconstruction quality. Below we show the visualization of how the \(g=3\) reconstruction changes with \(W\) going from \(0\%\) to \(100\%\).</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/assets/LenslessMic/video/audio_psferror_237-126133-0018.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" autoplay="" controls=""></video> </figure> <div class="caption"> 237-126133-0018 </div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/assets/LenslessMic/video/audio_psferror_8455-210777-0042.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" controls=""></video> </figure> <div class="caption"> 8455-210777-0042 </div> </div> </div> <h3 id="captured-video-representation">Captured Video Representation</h3> <p>Below we provide the examples of a video representation of audio obtained using DAC, its lensless measurement, and different reconstructions. Original framerate is \(20\) ms for each frame. To see details better, we slow video down to \(100\) ms per frame.</p> <div class="alert alert-warning" role="alert"> ⚠️ <strong>Content warning:</strong> The following video contains rapid flashing/blinking. It may trigger seizures for people with photosensitive epilepsy. <em>Viewer discretion is advised.</em> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/assets/LenslessMic/video/lensed.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" autoplay="" controls=""></video> </figure> <div class="caption"> Lensed </div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/assets/LenslessMic/video/lensless.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" controls=""></video> </figure> <div class="caption"> Lensless Measurement </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/assets/LenslessMic/video/learned.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" controls=""></video> </figure> <div class="caption"> Reconstruction (<em>Learned</em>) </div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/assets/LenslessMic/video/rlearned.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" controls=""></video> </figure> <div class="caption"> Reconstruction (<em>R-Learned</em>) </div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/assets/LenslessMic/video/nopsf.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" controls=""></video> </figure> <div class="caption"> Reconstruction (<em>NoPSF</em>) </div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/assets/LenslessMic/video/admm100.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" controls=""></video> </figure> <div class="caption"> Reconstruction (<em>ADMM-100</em>) </div> </div> </div> <div class="caption"> Example of a lensed video (audio-to-video conversion), a corresponding lensless measurement, and its reconstruction. Audio track: 237-126133-0018. </div> <p>We note that <em>NoPSF</em> often provides smoother frames than <em>Learned</em> and <em>R-Learned</em> that are more sharp. This means that <em>NoPSF</em> is not able to fully recover image from the multiplexing effect of lensless camera. <em>ADMM-100</em> completely fails to recover frames.</p> <p>The video below shows how reconstruction of the same frame enhances from \(W=0\%\) to \(W=100\%\). More specifically, we plot \(l_2\)-difference \((\hat{x}-x)^2\) between the reconstructed and codec frames.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/assets/LenslessMic/video/psferror.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" controls=""></video> </figure> <div class="caption"> Difference between reconstructed and codec frames vs W. The more dark is the image, the less different are the frames. </div> </div> </div> <h2 id="extra-experiments">Extra Experiments</h2> <p>We provide three additional experiments:</p> <ol> <li> <p>In the paper, we noted that the search space for brute-force attack can also be restricted by the RVQ of the codec. With \(C=12\) codebooks of size \(1024\) this leads to \(2^{120}\) possible codebook outputs. This is not an issue because the intruder will need to do it for all \(T_E\) frames, which leads to a search space of \(2^{120T_E}\). However, to be sure, one may fine-tune/train a neural audio codec to have a larger search space. We <a href="https://github.com/Blinorot/descript-audio-codec/blob/main/conf/custom/16x16_130_16khz.yml" rel="external nofollow noopener" target="_blank">fine-tuned</a> DAC on the full Librispeech corpus with \(C=13\) codebooks of size \(1024\) (i.e. search space of \(2^{130}\)) and \(16\times16\) latent representation. The decreased size of the latent representation allows to get even higher quality of reconstruction. We collected <em>train-clean</em> and <em>test-clean</em> variants for this codec.</p> </li> <li> <p>We showed that the method is applicable on different types of audio. However, it is also important to generalize to different environments and conditions. Even though DAC itself works on both clean and noisy speech, training only on <em>train-clean</em> can overfit the reconstruction algorithm on clean data. To account for this, we collected a small subset of \(150\) audio files from Librispeech <em>train-other</em> (see Tab 1. in the paper). We fine-tuned <em>Learned</em> (\(g=1\)) system on a mix of <em>train-other</em> and <em>train-clean</em> datasets with constant learning rate of \(2\cdot 10^{-5}\) for \(15\) K steps. We refer to this system as <em>FT-Learned</em>. (Remark: fine-tuning only on <em>train-other</em> leads to drop in performance on clean data, i.e., catastrophic forgetting phenomenon, so we use a mixture).</p> </li> <li> <p>(Only models, no tables). We investigated different loss functions. Our final combination \(\mathcal{L}_{\text{raw}, \text{SSIM}} + \mathcal{L}_{\text{SSIM}} + \mathcal{L}_{\text{MSE}}\) performs the best. Having only \(\mathcal{L}_{\text{MSE}}\) leads to poor convergence and suboptimal quality, showcasing the importance of the structure-based losses. Adding \(\mathcal{L}_{\text{SSIM}}\) to MSE helps a lot, however, having the third term \(\mathcal{L}_{\text{raw, SSIM}}\) further improves the quality. We investigated audio-based losses, such as \(l_1\)-distance between the waveforms or Mel spectrograms of codec and reconstructed audio, however, it had negative effect on the performance. We provide corresponding checkpoints on our <a href="https://huggingface.co/collections/Blinorot/lenslessmic-68caf4f8ff7fa56c2dac8540" rel="external nofollow noopener" target="_blank">Huggingface Collection</a>.</p> </li> </ol> <p>The results are provided below.</p> <table id="audio-table" data-toggle="table" data-search="false" data-pagination="true" data-url="/assets/json/LenslessMic/extra_exps.json" data-height="630"> <thead> <tr> <th data-field="method" data-sortable="true">Method</th> <th data-field="test_set" data-sortable="true">Test Set</th> <th data-field="g_r" data-sortable="true">g/r</th> <th data-field="psnr" data-sortable="true">PSNR</th> <th data-field="ssim" data-sortable="true">SSIM</th> <th data-field="mse" data-sortable="true">MSE</th> <th data-field="visqol" data-sortable="true">ViSQOL</th> <th data-field="sisdr" data-sortable="true">SI-SDR</th> <th data-field="mel" data-sortable="true">Mel</th> <th data-field="stoi" data-sortable="true">STOI</th> <th data-field="wer" data-sortable="true">WER</th> <th data-field="sma" data-sortable="true">SMA</th> <th data-field="qm" data-sortable="true">QM-1/2</th> </tr> </thead> </table> <p>We see that dicreased representation size (\(16\times 16\)) allows to improve reconstruction quality in comparison to <em>Learned</em> (\(32\times32\)) on <em>test-clean</em>, while also having a benefit of a bigger search space. For the <em>test-other</em>, we see that both <em>train-clean</em> or <em>train-random</em> are not enough for the reconstruction algorithm to perform on noisy data well. However, adding only small number of <em>train-other</em> samples into the training data enabled <em>FT-Learned</em> to achieve high reconstruction quality on both clean and noisy test sets. Hence, <em>LenslessMic</em> is applicable on noisy data too.</p> <p>Audio examples for \(16\times16\):</p> <table id="audio-table" data-toggle="table" data-search="false" data-pagination="true" data-url="/assets/json/LenslessMic/test_clean_all_16x16.json" data-height="350"> <thead> <tr> <th data-field="method" data-sortable="true">Method</th> <th data-field="237-126133-0018" data-formatter="audioFormatter" data-halign="center" data-align="center">237-126133-0018</th> <th data-field="4446-2273-0026" data-formatter="audioFormatter" data-halign="center" data-align="center">4446-2273-0026</th> <th data-field="5105-28241-0013" data-formatter="audioFormatter" data-halign="center" data-align="center">5105-28241-0013</th> <th data-field="5142-33396-0062" data-formatter="audioFormatter" data-halign="center" data-align="center">5142-33396-0062</th> <th data-field="7127-75947-0032" data-formatter="audioFormatter" data-halign="center" data-align="center">7127-75947-0032</th> <th data-field="8455-210777-0042" data-formatter="audioFormatter" data-halign="center" data-align="center">8455-210777-0042</th> </tr> </thead> </table> <p>Audio examples for <em>test-other</em>:</p> <table id="audio-table" data-toggle="table" data-search="false" data-pagination="true" data-url="/assets/json/LenslessMic/test_clean_all_other.json" data-height="550"> <thead> <tr> <th data-field="method" data-sortable="true">Method</th> <th data-field="2414-159411-0027" data-formatter="audioFormatter" data-halign="center" data-align="center">2414-159411-0027</th> <th data-field="3005-163389-0011" data-formatter="audioFormatter" data-halign="center" data-align="center">3005-163389-0011</th> <th data-field="3528-168669-0015" data-formatter="audioFormatter" data-halign="center" data-align="center">3528-168669-0015</th> <th data-field="3764-168670-0006" data-formatter="audioFormatter" data-halign="center" data-align="center">3764-168670-0006</th> <th data-field="4350-9170-0022" data-formatter="audioFormatter" data-halign="center" data-align="center">4350-9170-0022</th> <th data-field="7902-96595-0024" data-formatter="audioFormatter" data-halign="center" data-align="center">7902-96595-0024</th> </tr> </thead> </table> <p>Finnaly, we show that <em>FT-Learned</em> performs well on <em>test-clean</em> too:</p> <table id="audio-table" data-toggle="table" data-search="false" data-pagination="true" data-url="/assets/json/LenslessMic/test_clean_all_with_other.json" data-height="450"> <thead> <tr> <th data-field="method" data-sortable="true">Method</th> <th data-field="237-126133-0018" data-formatter="audioFormatter" data-halign="center" data-align="center">237-126133-0018</th> <th data-field="4446-2273-0026" data-formatter="audioFormatter" data-halign="center" data-align="center">4446-2273-0026</th> <th data-field="5105-28241-0013" data-formatter="audioFormatter" data-halign="center" data-align="center">5105-28241-0013</th> <th data-field="5142-33396-0062" data-formatter="audioFormatter" data-halign="center" data-align="center">5142-33396-0062</th> <th data-field="7127-75947-0032" data-formatter="audioFormatter" data-halign="center" data-align="center">7127-75947-0032</th> <th data-field="8455-210777-0042" data-formatter="audioFormatter" data-halign="center" data-align="center">8455-210777-0042</th> </tr> </thead> </table> </article> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Petr Grinberg. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script defer src="https://cdn.jsdelivr.net/npm/bootstrap-table@1.22.4/dist/bootstrap-table.min.js" integrity="sha256-4rppopQE9POKfukn2kEvhJ9Um25Cf6+IDVkARD0xh78=" crossorigin="anonymous"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?70d799092f862ad98c7876aa47712e20"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>